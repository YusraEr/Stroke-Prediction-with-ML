{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "def load_fold_data(sf, nfs):\n",
    "    \"\"\"\n",
    "    Memuat data lipatan (fold) yang ditentukan untuk prediksi stroke.\n",
    "    Args:\n",
    "        SF (int): Indeks lipatan yang akan dimuat dari data stroke.\n",
    "        NFS (int): Indeks lipatan yang akan dimuat dari data non-stroke.\n",
    "    Returns:\n",
    "        tuple: Mengembalikan dua elemen:\n",
    "            - training_data: Data training yang akan digunakan untuk melatih model.\n",
    "            - testing_data: Data testing yang akan digunakan untuk menguji model.\n",
    "    \"\"\"\n",
    "    # Load fold dari stroke data\n",
    "    stroke_fold = pd.read_csv(f'StrokeFold/stroke_fold_{sf}.csv')\n",
    "    remaining_stroke = [pd.read_csv(f'StrokeFold/stroke_fold_{i}.csv') for i in range(1, 6) if i != sf]\n",
    "    remaining_stroke = pd.concat(remaining_stroke)\n",
    "\n",
    "    # Load fold dari no stroke data\n",
    "    no_stroke_fold = pd.read_csv(f'NonStrokeFold/no_stroke_fold_{nfs}.csv')\n",
    "\n",
    "    # Ambil 100 data di no_stroke_fold sebagai testing\n",
    "    testing_no_stroke = no_stroke_fold.sample(n=100, random_state=42)\n",
    "\n",
    "    # Sisanya sebagai training\n",
    "    training_no_stroke = no_stroke_fold.drop(testing_no_stroke.index)\n",
    "\n",
    "    # Gabungkan data training stroke dan non-stroke\n",
    "    training_data = pd.concat([remaining_stroke, training_no_stroke])\n",
    "\n",
    "    # Gabungkan data testing stroke dan non-stroke\n",
    "    testing_data = pd.concat([stroke_fold, testing_no_stroke])\n",
    "    \n",
    "    # Inisialisasi SMOTE\n",
    "    smote = SMOTE(sampling_strategy=0.7, random_state=42)\n",
    "    \n",
    "    # Terapkan SMOTE pada data training\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(training_data.drop(columns=['stroke']), training_data['stroke'])\n",
    "\n",
    "    # Gabungkan kembali data yang telah di-resample\n",
    "    training_data = pd.concat([X_train_smote, y_train_smote], axis=1)\n",
    "\n",
    "    return training_data, testing_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_fold_data_ns(sf, nfs):\n",
    "    \"\"\"\n",
    "    Memuat data lipatan (fold) yang ditentukan untuk prediksi stroke.\n",
    "    Args:\n",
    "        SF (int): Indeks lipatan yang akan dimuat dari data stroke.\n",
    "        NFS (int): Indeks lipatan yang akan dimuat dari data non-stroke.\n",
    "    Returns:\n",
    "        tuple: Mengembalikan dua elemen:\n",
    "            - training_data: Data training yang akan digunakan untuk melatih model.\n",
    "            - testing_data: Data testing yang akan digunakan untuk menguji model.\n",
    "    \"\"\"\n",
    "    # Load fold dari stroke data\n",
    "    stroke_fold = pd.read_csv(f'StrokeFold/stroke_fold_{sf}.csv')\n",
    "    remaining_stroke = [pd.read_csv(f'StrokeFold/stroke_fold_{i}.csv') for i in range(1, 6) if i != sf]\n",
    "    remaining_stroke = pd.concat(remaining_stroke)\n",
    "\n",
    "    # Load fold dari no stroke data\n",
    "    no_stroke_fold = pd.read_csv(f'NonStrokeFold/no_stroke_fold_{nfs}.csv')\n",
    "\n",
    "    # Ambil 100 data di no_stroke_fold sebagai testing\n",
    "    testing_no_stroke = no_stroke_fold.sample(n=100, random_state=42)\n",
    "\n",
    "    # Sisanya sebagai training\n",
    "    training_no_stroke = no_stroke_fold.drop(testing_no_stroke.index)\n",
    "    \n",
    "    #mengambil fold dari data non stroke yang tersisa\n",
    "    remaining_no_stroke = [pd.read_csv(f'NonStrokeFold/no_stroke_fold_{i}.csv') for i in range(1, 6) if i != nfs]\n",
    "    remaining_no_stroke = pd.concat(remaining_no_stroke)\n",
    "\n",
    "    # Gabungkan data training stroke dan non-stroke\n",
    "    training_data = pd.concat([remaining_stroke, training_no_stroke, remaining_no_stroke])\n",
    "\n",
    "    # Gabungkan data testing stroke dan non-stroke\n",
    "    testing_data = pd.concat([stroke_fold, testing_no_stroke])\n",
    "\n",
    "    return training_data, testing_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "def cross_validation(model, func):\n",
    "    results = []\n",
    "# Loop through all combinations of folds dengan progress bar\n",
    "    for sf in tqdm(range(1, 6), desc=\"Stroke Folds\"):\n",
    "        for nfs in tqdm(range(1, 6), desc=\"Non-Stroke Folds\", leave=False):\n",
    "            train_data, test_data = func(sf, nfs)\n",
    "\n",
    "            # Pisahkan fitur dan target untuk data train dan test\n",
    "            X_train = train_data.drop(columns=['stroke'])\n",
    "            y_train = train_data['stroke']\n",
    "            X_test = test_data.drop(columns=['stroke'])\n",
    "            y_test = test_data['stroke']\n",
    "\n",
    "            # Latih model\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Prediksi pada data test\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Evaluasi model\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "            # Simpan hasil dalam dataframe\n",
    "            results.append({\n",
    "                'Stroke Fold': sf,\n",
    "                'Non-Stroke Fold': nfs,\n",
    "                'Accuracy': accuracy,\n",
    "                'Precision (Weighted Avg)': report['weighted avg']['precision'],\n",
    "                'Recall (Weighted Avg)': report['weighted avg']['recall'],\n",
    "                'F1-Score (Weighted Avg)': report['weighted avg']['f1-score'],\n",
    "                'Precision (Macro Avg)': report['macro avg']['precision'],\n",
    "                'Recall (Macro Avg)': report['macro avg']['recall'],\n",
    "                'F1-Score (Macro Avg)': report['macro avg']['f1-score']\n",
    "            })\n",
    "    # Buat DataFrame dari hasil\n",
    "    result_df = pd.DataFrame(results)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Stroke Folds: 100%|██████████| 5/5 [00:01<00:00,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Stroke Fold  Non-Stroke Fold  Accuracy  Precision (Weighted Avg)  Recall (Weighted Avg)  F1-Score (Weighted Avg)  Precision (Macro Avg)  Recall (Macro Avg)  F1-Score (Macro Avg)\n",
      "0             1                1  0.740000                  0.744213               0.740000                 0.741807               0.709103            0.715000              0.711695\n",
      "1             1                2  0.746667                  0.744281               0.746667                 0.745336               0.714461            0.710000              0.712063\n",
      "2             1                3  0.686667                  0.695056               0.686667                 0.690110               0.653110            0.660000              0.655678\n",
      "3             1                4  0.746667                  0.744281               0.746667                 0.745336               0.714461            0.710000              0.712063\n",
      "4             1                5  0.773333                  0.768153               0.773333                 0.769400               0.746569            0.730000              0.736625\n",
      "5             2                1  0.760000                  0.760000               0.760000                 0.760000               0.730000            0.730000              0.730000\n",
      "6             2                2  0.746667                  0.746667               0.746667                 0.746667               0.715000            0.715000              0.715000\n",
      "7             2                3  0.706667                  0.720140               0.706667                 0.711420               0.678036            0.690000              0.681713\n",
      "8             2                4  0.780000                  0.777112               0.780000                 0.778224               0.753047            0.745000              0.748616\n",
      "9             2                5  0.780000                  0.775661               0.780000                 0.776893               0.753968            0.740000              0.745828\n",
      "10            3                1  0.758389                  0.770942               0.758389                 0.762473               0.730931            0.747143              0.736439\n",
      "11            3                2  0.771812                  0.777241               0.771812                 0.773958               0.742630            0.751939              0.746599\n",
      "12            3                3  0.718121                  0.744585               0.718121                 0.725130               0.696382            0.717143              0.699597\n",
      "13            3                4  0.785235                  0.787655               0.785235                 0.786298               0.756803            0.761939              0.759192\n",
      "14            3                5  0.812081                  0.812081               0.812081                 0.812081               0.787143            0.787143              0.787143\n",
      "15            4                1  0.744966                  0.761827               0.744966                 0.750062               0.718832            0.737143              0.724074\n",
      "16            4                2  0.771812                  0.777241               0.771812                 0.773958               0.742630            0.751939              0.746599\n",
      "17            4                3  0.704698                  0.722734               0.704698                 0.710598               0.676742            0.691531              0.680507\n",
      "18            4                4  0.778523                  0.782379               0.778523                 0.780126               0.749603            0.756939              0.752877\n",
      "19            4                5  0.798658                  0.798658               0.798658                 0.798658               0.771939            0.771939              0.771939\n",
      "20            5                1  0.771812                  0.787889               0.771812                 0.776371               0.746893            0.767551              0.753119\n",
      "21            5                2  0.778523                  0.782379               0.778523                 0.780126               0.749603            0.756939              0.752877\n",
      "22            5                3  0.731544                  0.753058               0.731544                 0.737619               0.707340            0.727143              0.711799\n",
      "23            5                4  0.791946                  0.798540               0.791946                 0.794329               0.764912            0.777347              0.770027\n",
      "24            5                5  0.812081                  0.814248               0.812081                 0.813011               0.786615            0.792347              0.789293\n",
      "       Stroke Fold  Non-Stroke Fold   Accuracy  Precision (Weighted Avg)  Recall (Weighted Avg)  F1-Score (Weighted Avg)  Precision (Macro Avg)  Recall (Macro Avg)  F1-Score (Macro Avg)\n",
      "count    25.000000        25.000000  25.000000                 25.000000              25.000000                25.000000              25.000000           25.000000             25.000000\n",
      "mean      3.000000         3.000000   0.759875                  0.765881               0.759875                 0.761600               0.731870            0.737645              0.733254\n",
      "std       1.443376         1.443376   0.032701                  0.028896               0.032701                 0.031253               0.033662            0.032022              0.033131\n",
      "min       1.000000         1.000000   0.686667                  0.695056               0.686667                 0.690110               0.653110            0.660000              0.655678\n",
      "25%       2.000000         2.000000   0.744966                  0.744585               0.744966                 0.745336               0.714461            0.715000              0.712063\n",
      "50%       3.000000         3.000000   0.771812                  0.770942               0.771812                 0.769400               0.742630            0.740000              0.736625\n",
      "75%       4.000000         4.000000   0.780000                  0.782379               0.780000                 0.780126               0.753047            0.756939              0.752877\n",
      "max       5.000000         5.000000   0.812081                  0.814248               0.812081                 0.813011               0.787143            0.792347              0.789293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Inisialisasi model Logistic Regression dengan max_iter yang lebih tinggi\n",
    "logistic_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "def cross_validation_scaled(model, func):\n",
    "\tresults = []\n",
    "\tfor sf in tqdm(range(1, 6), desc=\"Stroke Folds\"):\n",
    "\t\tfor nfs in tqdm(range(1, 6), desc=\"Non-Stroke Folds\", leave=False):\n",
    "\t\t\ttrain_data, test_data = func(sf, nfs)\n",
    "\n",
    "\t\t\t# Pisahkan fitur dan target untuk data train dan test\n",
    "\t\t\tX_train = train_data.drop(columns=['stroke'])\n",
    "\t\t\ty_train = train_data['stroke']\n",
    "\t\t\tX_test = test_data.drop(columns=['stroke'])\n",
    "\t\t\ty_test = test_data['stroke']\n",
    "\n",
    "\t\t\t# Scale the data\n",
    "\t\t\tX_train = scaler.fit_transform(X_train)\n",
    "\t\t\tX_test = scaler.transform(X_test)\n",
    "\n",
    "\t\t\t# Latih model\n",
    "\t\t\tmodel.fit(X_train, y_train)\n",
    "\n",
    "\t\t\t# Prediksi pada data test\n",
    "\t\t\ty_pred = model.predict(X_test)\n",
    "\n",
    "\t\t\t# Evaluasi model\n",
    "\t\t\taccuracy = accuracy_score(y_test, y_pred)\n",
    "\t\t\treport = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "\t\t\t# Simpan hasil dalam dataframe\n",
    "\t\t\tresults.append({\n",
    "\t\t\t\t'Stroke Fold': sf,\n",
    "\t\t\t\t'Non-Stroke Fold': nfs,\n",
    "\t\t\t\t'Accuracy': accuracy,\n",
    "\t\t\t\t'Precision (Weighted Avg)': report['weighted avg']['precision'],\n",
    "\t\t\t\t'Recall (Weighted Avg)': report['weighted avg']['recall'],\n",
    "\t\t\t\t'F1-Score (Weighted Avg)': report['weighted avg']['f1-score'],\n",
    "\t\t\t\t'Precision (Macro Avg)': report['macro avg']['precision'],\n",
    "\t\t\t\t'Recall (Macro Avg)': report['macro avg']['recall'],\n",
    "\t\t\t\t'F1-Score (Macro Avg)': report['macro avg']['f1-score']\n",
    "\t\t\t})\n",
    "\t# Buat DataFrame dari hasil\n",
    "\tresult_df = pd.DataFrame(results)\n",
    "\treturn result_df\n",
    "\n",
    "results = cross_validation_scaled(logistic_model, load_fold_data)\n",
    "\n",
    "print(results)\n",
    "print(results.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stroke Folds: 100%|██████████| 5/5 [00:01<00:00,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Stroke Fold  Non-Stroke Fold  Accuracy  Precision (Weighted Avg)  Recall (Weighted Avg)  F1-Score (Weighted Avg)  Precision (Macro Avg)  Recall (Macro Avg)  F1-Score (Macro Avg)\n",
      "0             1                1  0.666667                  0.444444               0.666667                 0.533333               0.333333                 0.5              0.400000\n",
      "1             1                2  0.666667                  0.444444               0.666667                 0.533333               0.333333                 0.5              0.400000\n",
      "2             1                3  0.666667                  0.444444               0.666667                 0.533333               0.333333                 0.5              0.400000\n",
      "3             1                4  0.666667                  0.444444               0.666667                 0.533333               0.333333                 0.5              0.400000\n",
      "4             1                5  0.666667                  0.444444               0.666667                 0.533333               0.333333                 0.5              0.400000\n",
      "5             2                1  0.666667                  0.444444               0.666667                 0.533333               0.333333                 0.5              0.400000\n",
      "6             2                2  0.666667                  0.444444               0.666667                 0.533333               0.333333                 0.5              0.400000\n",
      "7             2                3  0.666667                  0.444444               0.666667                 0.533333               0.333333                 0.5              0.400000\n",
      "8             2                4  0.666667                  0.444444               0.666667                 0.533333               0.333333                 0.5              0.400000\n",
      "9             2                5  0.666667                  0.444444               0.666667                 0.533333               0.333333                 0.5              0.400000\n",
      "10            3                1  0.671141                  0.450430               0.671141                 0.539069               0.335570                 0.5              0.401606\n",
      "11            3                2  0.671141                  0.450430               0.671141                 0.539069               0.335570                 0.5              0.401606\n",
      "12            3                3  0.671141                  0.450430               0.671141                 0.539069               0.335570                 0.5              0.401606\n",
      "13            3                4  0.671141                  0.450430               0.671141                 0.539069               0.335570                 0.5              0.401606\n",
      "14            3                5  0.671141                  0.450430               0.671141                 0.539069               0.335570                 0.5              0.401606\n",
      "15            4                1  0.671141                  0.450430               0.671141                 0.539069               0.335570                 0.5              0.401606\n",
      "16            4                2  0.671141                  0.450430               0.671141                 0.539069               0.335570                 0.5              0.401606\n",
      "17            4                3  0.671141                  0.450430               0.671141                 0.539069               0.335570                 0.5              0.401606\n",
      "18            4                4  0.671141                  0.450430               0.671141                 0.539069               0.335570                 0.5              0.401606\n",
      "19            4                5  0.671141                  0.450430               0.671141                 0.539069               0.335570                 0.5              0.401606\n",
      "20            5                1  0.671141                  0.450430               0.671141                 0.539069               0.335570                 0.5              0.401606\n",
      "21            5                2  0.671141                  0.450430               0.671141                 0.539069               0.335570                 0.5              0.401606\n",
      "22            5                3  0.671141                  0.450430               0.671141                 0.539069               0.335570                 0.5              0.401606\n",
      "23            5                4  0.671141                  0.450430               0.671141                 0.539069               0.335570                 0.5              0.401606\n",
      "24            5                5  0.671141                  0.450430               0.671141                 0.539069               0.335570                 0.5              0.401606\n",
      "       Stroke Fold  Non-Stroke Fold   Accuracy  Precision (Weighted Avg)  Recall (Weighted Avg)  F1-Score (Weighted Avg)  Precision (Macro Avg)  Recall (Macro Avg)  F1-Score (Macro Avg)\n",
      "count    25.000000        25.000000  25.000000                 25.000000              25.000000                25.000000              25.000000                25.0             25.000000\n",
      "mean      3.000000         3.000000   0.669351                  0.448036               0.669351                 0.536775               0.334676                 0.5              0.400964\n",
      "std       1.443376         1.443376   0.002237                  0.002993               0.002237                 0.002868               0.001119                 0.0              0.000803\n",
      "min       1.000000         1.000000   0.666667                  0.444444               0.666667                 0.533333               0.333333                 0.5              0.400000\n",
      "25%       2.000000         2.000000   0.666667                  0.444444               0.666667                 0.533333               0.333333                 0.5              0.400000\n",
      "50%       3.000000         3.000000   0.671141                  0.450430               0.671141                 0.539069               0.335570                 0.5              0.401606\n",
      "75%       4.000000         4.000000   0.671141                  0.450430               0.671141                 0.539069               0.335570                 0.5              0.401606\n",
      "max       5.000000         5.000000   0.671141                  0.450430               0.671141                 0.539069               0.335570                 0.5              0.401606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "results = cross_validation_scaled(logistic_model, load_fold_data_ns)\n",
    "print(results)\n",
    "print(results.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    for j in range(1, 6):\n",
    "        # Definisikan ruang pencarian untuk hyperparameter\n",
    "        param_space = {\n",
    "            'C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
    "            'solver': ['newton-cg', 'lbfgs', 'liblinear']\n",
    "        }\n",
    "\n",
    "        # Inisialisasi model RandomForestClassifier\n",
    "        logistic_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "        # Inisialisasi BayesSearchCV\n",
    "        opt = BayesSearchCV(\n",
    "            logistic_model,\n",
    "            param_space,\n",
    "            n_iter=32,\n",
    "            cv=3,\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Latih model dengan optimasi Bayesian\n",
    "        train_data, test_data = load_fold_data(i, j)\n",
    "        X_train = train_data.drop(columns=['stroke'])\n",
    "        y_train = train_data['stroke']\n",
    "        X_test = test_data.drop(columns=['stroke'])\n",
    "        y_test = test_data['stroke']\n",
    "        opt.fit(X_train, y_train)\n",
    "\n",
    "        # Simpan hasil terbaik\n",
    "        best_params = opt.best_params_\n",
    "        best_score = opt.best_score_\n",
    "\n",
    "        # Prediksi pada data test\n",
    "        y_pred_opt = opt.predict(X_test)\n",
    "\n",
    "        # Evaluasi model\n",
    "        accuracy_opt = accuracy_score(y_test, y_pred_opt)\n",
    "        report_opt = classification_report(y_test, y_pred_opt, target_names=['No Stroke', 'Stroke'], output_dict=True)\n",
    "\n",
    "        # Simpan hasil dalam dataframe\n",
    "        results.append({\n",
    "            'Stroke Fold': i,\n",
    "            'Non-Stroke Fold': j,\n",
    "            'Best Parameters': best_params,\n",
    "            'Best Score': best_score,\n",
    "            'Accuracy': accuracy_opt,\n",
    "            'Precision': report_opt['weighted avg']['precision'],\n",
    "            'Recall': report_opt['weighted avg']['recall'],\n",
    "            'F1-Score': report_opt['weighted avg']['f1-score']\n",
    "        })\n",
    "\n",
    "# Buat DataFrame dari hasil\n",
    "result_best_parameters = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Stroke Fold  Non-Stroke Fold                                    Best Parameters  Best Score  Accuracy  Precision    Recall  F1-Score\n",
      "0             1                1   {'C': 11185.625288472094, 'solver': 'liblinear'}    0.764465  0.740000   0.744213  0.740000  0.741807\n",
      "1             1                2    {'C': 0.0004309780808920444, 'solver': 'lbfgs'}    0.756507  0.760000   0.755853  0.760000  0.757353\n",
      "2             1                3   {'C': 1.6363876753596596, 'solver': 'liblinear'}    0.746432  0.686667   0.695056  0.686667  0.690110\n",
      "3             1                4    {'C': 3.317697704417197, 'solver': 'liblinear'}    0.756507  0.746667   0.744281  0.746667  0.745336\n",
      "4             1                5    {'C': 3.317697704417197, 'solver': 'liblinear'}    0.762385  0.773333   0.768153  0.773333  0.769400\n",
      "5             2                1   {'C': 25.406936492978463, 'solver': 'liblinear'}    0.762790  0.760000   0.760000  0.760000  0.760000\n",
      "6             2                2   {'C': 0.00010646072012413247, 'solver': 'lbfgs'}    0.768262  0.780000   0.775661  0.780000  0.776893\n",
      "7             2                3  {'C': 0.001861880497250463, 'solver': 'newton-...    0.751469  0.693333   0.711111  0.693333  0.699203\n",
      "8             2                4    {'C': 3.317697704417197, 'solver': 'liblinear'}    0.755668  0.780000   0.777112  0.780000  0.778224\n",
      "9             2                5   {'C': 11185.625288472094, 'solver': 'liblinear'}    0.769102  0.780000   0.775661  0.780000  0.776893\n",
      "10            3                1   {'C': 25.406936492978463, 'solver': 'liblinear'}    0.751891  0.758389   0.770942  0.758389  0.762473\n",
      "11            3                2  {'C': 0.05025673350467898, 'solver': 'newton-cg'}    0.749790  0.771812   0.777241  0.771812  0.773958\n",
      "12            3                3   {'C': 0.4848890160401785, 'solver': 'newton-cg'}    0.739715  0.718121   0.744585  0.718121  0.725130\n",
      "13            3                4   {'C': 0.00033125146929023874, 'solver': 'lbfgs'}    0.743913  0.785235   0.787655  0.785235  0.786298\n",
      "14            3                5   {'C': 0.1199876106129895, 'solver': 'newton-cg'}    0.751469  0.812081   0.812081  0.812081  0.812081\n",
      "15            4                1    {'C': 3.317697704417197, 'solver': 'liblinear'}    0.748531  0.744966   0.761827  0.744966  0.750062\n",
      "16            4                2    {'C': 0.0004192214618350736, 'solver': 'lbfgs'}    0.744752  0.791946   0.793077  0.791946  0.792474\n",
      "17            4                3  {'C': 0.0013717237663828127, 'solver': 'newton...    0.734677  0.704698   0.727023  0.704698  0.711381\n",
      "18            4                4  {'C': 0.00011465965122563988, 'solver': 'newto...    0.741394  0.798658   0.800951  0.798658  0.799654\n",
      "19            4                5  {'C': 0.06330864699390906, 'solver': 'newton-cg'}    0.756507  0.805369   0.806433  0.805369  0.805863\n",
      "20            5                1   {'C': 11185.625288472094, 'solver': 'liblinear'}    0.757756  0.771812   0.787889  0.771812  0.776371\n",
      "21            5                2   {'C': 10.730171214409959, 'solver': 'liblinear'}    0.759026  0.778523   0.782379  0.778523  0.780126\n",
      "22            5                3   {'C': 1.1680553946455452, 'solver': 'liblinear'}    0.741394  0.731544   0.753058  0.731544  0.737619\n",
      "23            5                4    {'C': 3.317697704417197, 'solver': 'liblinear'}    0.754828  0.791946   0.798540  0.791946  0.794329\n",
      "24            5                5   {'C': 2.4525835016562225, 'solver': 'liblinear'}    0.768262  0.818792   0.819790  0.818792  0.819252\n"
     ]
    }
   ],
   "source": [
    "print(result_best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stroke Folds: 100%|██████████| 5/5 [00:01<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Stroke Fold  Non-Stroke Fold  Accuracy  Precision (Weighted Avg)  Recall (Weighted Avg)  F1-Score (Weighted Avg)  Precision (Macro Avg)  Recall (Macro Avg)  F1-Score (Macro Avg)\n",
      "0             1                1  0.740000                  0.744213               0.740000                 0.741807               0.709103            0.715000              0.711695\n",
      "1             1                2  0.746667                  0.744281               0.746667                 0.745336               0.714461            0.710000              0.712063\n",
      "2             1                3  0.686667                  0.695056               0.686667                 0.690110               0.653110            0.660000              0.655678\n",
      "3             1                4  0.746667                  0.744281               0.746667                 0.745336               0.714461            0.710000              0.712063\n",
      "4             1                5  0.773333                  0.768153               0.773333                 0.769400               0.746569            0.730000              0.736625\n",
      "5             2                1  0.760000                  0.760000               0.760000                 0.760000               0.730000            0.730000              0.730000\n",
      "6             2                2  0.746667                  0.746667               0.746667                 0.746667               0.715000            0.715000              0.715000\n",
      "7             2                3  0.706667                  0.720140               0.706667                 0.711420               0.678036            0.690000              0.681713\n",
      "8             2                4  0.780000                  0.777112               0.780000                 0.778224               0.753047            0.745000              0.748616\n",
      "9             2                5  0.780000                  0.775661               0.780000                 0.776893               0.753968            0.740000              0.745828\n",
      "10            3                1  0.758389                  0.770942               0.758389                 0.762473               0.730931            0.747143              0.736439\n",
      "11            3                2  0.771812                  0.777241               0.771812                 0.773958               0.742630            0.751939              0.746599\n",
      "12            3                3  0.718121                  0.744585               0.718121                 0.725130               0.696382            0.717143              0.699597\n",
      "13            3                4  0.785235                  0.787655               0.785235                 0.786298               0.756803            0.761939              0.759192\n",
      "14            3                5  0.812081                  0.812081               0.812081                 0.812081               0.787143            0.787143              0.787143\n",
      "15            4                1  0.744966                  0.761827               0.744966                 0.750062               0.718832            0.737143              0.724074\n",
      "16            4                2  0.771812                  0.777241               0.771812                 0.773958               0.742630            0.751939              0.746599\n",
      "17            4                3  0.704698                  0.722734               0.704698                 0.710598               0.676742            0.691531              0.680507\n",
      "18            4                4  0.778523                  0.782379               0.778523                 0.780126               0.749603            0.756939              0.752877\n",
      "19            4                5  0.798658                  0.798658               0.798658                 0.798658               0.771939            0.771939              0.771939\n",
      "20            5                1  0.771812                  0.787889               0.771812                 0.776371               0.746893            0.767551              0.753119\n",
      "21            5                2  0.778523                  0.782379               0.778523                 0.780126               0.749603            0.756939              0.752877\n",
      "22            5                3  0.731544                  0.753058               0.731544                 0.737619               0.707340            0.727143              0.711799\n",
      "23            5                4  0.791946                  0.798540               0.791946                 0.794329               0.764912            0.777347              0.770027\n",
      "24            5                5  0.812081                  0.814248               0.812081                 0.813011               0.786615            0.792347              0.789293\n",
      "       Stroke Fold  Non-Stroke Fold   Accuracy  Precision (Weighted Avg)  Recall (Weighted Avg)  F1-Score (Weighted Avg)  Precision (Macro Avg)  Recall (Macro Avg)  F1-Score (Macro Avg)\n",
      "count    25.000000        25.000000  25.000000                 25.000000              25.000000                25.000000              25.000000           25.000000             25.000000\n",
      "mean      3.000000         3.000000   0.759875                  0.765881               0.759875                 0.761600               0.731870            0.737645              0.733254\n",
      "std       1.443376         1.443376   0.032701                  0.028896               0.032701                 0.031253               0.033662            0.032022              0.033131\n",
      "min       1.000000         1.000000   0.686667                  0.695056               0.686667                 0.690110               0.653110            0.660000              0.655678\n",
      "25%       2.000000         2.000000   0.744966                  0.744585               0.744966                 0.745336               0.714461            0.715000              0.712063\n",
      "50%       3.000000         3.000000   0.771812                  0.770942               0.771812                 0.769400               0.742630            0.740000              0.736625\n",
      "75%       4.000000         4.000000   0.780000                  0.782379               0.780000                 0.780126               0.753047            0.756939              0.752877\n",
      "max       5.000000         5.000000   0.812081                  0.814248               0.812081                 0.813011               0.787143            0.792347              0.789293\n"
     ]
    }
   ],
   "source": [
    "model_best = LogisticRegression(C=best_params['C'], random_state=42, solver=best_params['solver'], max_iter=1000)\n",
    "\n",
    "cross_validation_scaled(model_best, load_fold_data)\n",
    "\n",
    "print(results)\n",
    "print(results.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
